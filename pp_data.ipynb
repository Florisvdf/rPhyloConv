{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif, f_regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "uni_feat_percent=30\n",
    "occurrence_ratio = 0.90\n",
    "try:\n",
    "    os.mkdir(\"processed_data\")\n",
    "except OSError:\n",
    "    print(\"Directory already exists\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "neg_ids = pd.read_csv(\"input_data/patient_ids_neg.csv\").values[:, 0].astype(str)\n",
    "pos_ids = pd.read_csv(\"input_data/patient_ids_pos.csv\").values[:, 0].astype(str)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def filter_features(X, min_occurence_ratio):\n",
    "    print(\"Original dimensions: {}\".format(X.shape))\n",
    "    # Filters out the features that are constant\n",
    "    X = X[:, np.invert(np.all(X == X[0,:], axis = 0))]\n",
    "    print(\"Dimensions after filtering out constant features: {}\".format(X.shape))\n",
    "    # Filters out features that have more than min_occurence_ratio of n_subjects zero counts\n",
    "    # Aka, the feature has to occur in at least min_occurence_ratio of the samples\n",
    "    X = X[:, (X == 0).sum(axis =0 ) < X.shape[0] * min_occurence_ratio]\n",
    "    print(\"Dimensions after filtering based on an occurence threshold of {}: {}\".format(min_occurence_ratio, X.shape))\n",
    "    # makes a new column with the sum of the values in each column of a row is <20\n",
    "    # removing all rows that have less than 5% of counts more than 20\n",
    "    return X"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Data loading\n",
      "\n",
      "Finished\n"
     ]
    }
   ],
   "source": [
    "print('Data loading')\n",
    "print('')\n",
    "X_train_df=pd.read_csv(filepath_or_buffer='input_data/X_train.csv',\n",
    "                       index_col = 0)\n",
    "y_train_df=pd.read_csv(filepath_or_buffer = 'input_data/aTPO_no_meds.csv',\n",
    "                       index_col='Heliusnr')\n",
    "X_train_df.fillna(method='ffill',inplace=True)\n",
    "print('Finished')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train_df.transpose()\n",
    "y_train_df = y_train_df.sort_index(axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df_pos = X_train_df.loc[pos_ids]\n",
    "X_train_df_neg = X_train_df.loc[neg_ids]\n",
    "X_train_df_total = pd.concat([X_train_df_pos, X_train_df_neg], axis = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_binary = np.concatenate((np.zeros(143), np.ones(143)))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_full = X_train_df_total.values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Original dimensions: (286, 21443)\n",
      "Dimensions after filtering out constant features: (286, 14462)\n",
      "Dimensions after filtering based on an occurence threshold of 0.9: (286, 1497)\n"
     ]
    }
   ],
   "source": [
    "# Filtering out features\n",
    "X_full = filter_features(X_full, occurrence_ratio)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "selected_features = {}\n",
    "selected_features[\"Features\"] = []\n",
    "selected_features[\"Scores\"] = []\n",
    "selected_features[\"p_values\"] = []\n",
    "\n",
    "list_feat_names = []\n",
    "list_feat_importances = []\n",
    "\n",
    "auc_dict = {}\n",
    "auc_dict[\"TPR\"] = []\n",
    "auc_dict[\"FPR\"] = []\n",
    "auc_dict[\"Thresholds\"] = []\n",
    "auc_dict[\"AUC\"] = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Number of features after feature selection: 449\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\sklearn\\utils\\validation.py:70: FutureWarning: Pass percentile=30 as keyword args. From version 0.25 passing these as positional arguments will result in an error\n",
      "  FutureWarning)\n"
     ]
    }
   ],
   "source": [
    "b = SelectPercentile(f_classif,uni_feat_percent)\n",
    "b.fit(X_full, y_binary)\n",
    "X = X_full[:, b.get_support(indices=True)]\n",
    "y = y_binary\n",
    "selected_features[\"Features\"] = X_train_df_total.columns[b.get_support(indices=True)]\n",
    "feat_names = selected_features[\"Features\"]\n",
    "selected_features[\"Scores\"] = b.scores_[b.get_support(indices=True)]\n",
    "selected_features[\"p_values\"] = b.pvalues_[b.get_support(indices=True)]\n",
    "print(\"Number of features after feature selection: {}\".format(len(X[0])))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "X_train_df = X_train_df_total.iloc[:, b.get_support(indices=True)]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "np.save(\"processed_data/X.npy\", X)\n",
    "np.save(\"processed_data/y.npy\", y)\n",
    "X_train_df.to_csv(\"processed_data/X.csv\")"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
