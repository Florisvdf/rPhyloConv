{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Dependencies"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:516: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:517: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:518: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:519: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:520: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\framework\\dtypes.py:525: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:541: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint8 = np.dtype([(\"qint8\", np.int8, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:542: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint8 = np.dtype([(\"quint8\", np.uint8, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:543: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint16 = np.dtype([(\"qint16\", np.int16, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:544: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_quint16 = np.dtype([(\"quint16\", np.uint16, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:545: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  _np_qint32 = np.dtype([(\"qint32\", np.int32, 1)])\n",
      "C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorboard\\compat\\tensorflow_stub\\dtypes.py:550: FutureWarning: Passing (type, 1) or '1type' as a synonym of type is deprecated; in a future version of numpy, it will be understood as (type, (1,)) / '(1,)type'.\n",
      "  np_resource = np.dtype([(\"resource\", np.ubyte, 1)])\n"
     ]
    }
   ],
   "source": [
    "import pickle\n",
    "import struct\n",
    "import random\n",
    "import os\n",
    "import time\n",
    "\n",
    "import numpy as np\n",
    "from numpy import unique\n",
    "import pandas as pd\n",
    "from array import array as pyarray\n",
    "from scipy import sparse, interp\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "\n",
    "from sklearn.metrics import roc_curve, auc, mean_absolute_error,accuracy_score, mean_squared_error\n",
    "from sklearn.preprocessing import MinMaxScaler\n",
    "from sklearn.pipeline import Pipeline\n",
    "from sklearn.model_selection import StratifiedKFold, KFold, StratifiedShuffleSplit, ShuffleSplit, GridSearchCV, ParameterGrid, train_test_split\n",
    "from sklearn.metrics import roc_auc_score, matthews_corrcoef, precision_score, recall_score, f1_score\n",
    "from sklearn.feature_selection import SelectPercentile, f_classif\n",
    "from sklearn.base import BaseEstimator, RegressorMixin, TransformerMixin\n",
    "\n",
    "from Bio import Phylo\n",
    "\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras import backend as K\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.wrappers.scikit_learn import KerasRegressor\n",
    "from tensorflow.keras.metrics import AUC\n",
    "from tensorflow.keras.callbacks import EarlyStopping\n",
    "\n",
    "from joblib import Parallel, delayed\n",
    "import multiprocessing\n",
    "from copy import deepcopy\n",
    "\n",
    "from models import build_model\n",
    "from utils.io import group_by_params\n",
    "from utils.treebuilding import TreeBuilder"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Settings"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Directory already exists\n"
     ]
    }
   ],
   "source": [
    "np.random.seed(256)\n",
    "random_seed = 42\n",
    "n_shuffles = 1\n",
    "test_data_ratio=0.2\n",
    "n_cv_folds = 5\n",
    "train_ratio = 1\n",
    "\n",
    "tree_path = \"tree.tree\" \n",
    "\n",
    "path = str(np.loadtxt(\"path.txt\", dtype = str))\n",
    "\n",
    "try:\n",
    "    os.mkdir(\"output_data\")\n",
    "except OSError:\n",
    "    print(\"Directory already exists\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Loading data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "X = pd.read_csv(\"{}/X.csv\".format(path))\n",
    "y = np.load(\"{}/y.npy\".format(path)).astype(int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "label_names = {0:'aTPO Negative', 1:'aTPO Positive'}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Nested CV"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "auc_dict = {}\n",
    "auc_dict[\"TPR\"] = []\n",
    "auc_dict[\"FPR\"] = []\n",
    "auc_dict[\"Thresholds\"] = []\n",
    "auc_dict[\"AUC\"] = []\n",
    "\n",
    "list_auc=[]\n",
    "tprs = []\n",
    "aucs = []\n",
    "mean_fpr = np.linspace(0, 1, 100)\n",
    "shuffle_counter = 0\n",
    "\n",
    "StratShufSpl = StratifiedShuffleSplit(n_shuffles,\n",
    "                                    test_size = test_data_ratio, \n",
    "                                    random_state = random_seed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(286, 450)\n",
      "<class 'pandas.core.frame.DataFrame'>\n",
      "----------------------------------------------------------------\n",
      "Beginning stability selection iteration 0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Performing GridSearchCV for 5 candidates\n",
      "\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning cross validation for candidate number 0\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Total size of the training set: 182\n",
      "Total size of the validation set: 46\n",
      "Class frequencies in the training set: [0.5 0.5]\n",
      "Class frequencies in the validation set: [0.5 0.5]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning the tree building procedure\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Fitting candidate number 1 in shuffle 1 with parameters\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "WARNING:tensorflow:From C:\\Users\\Flori\\anaconda3\\lib\\site-packages\\tensorflow\\python\\ops\\init_ops.py:1251: calling VarianceScaling.__init__ (from tensorflow.python.ops.init_ops) with dtype is deprecated and will be removed in a future version.\n",
      "Instructions for updating:\n",
      "Call initializer instance with the dtype argument instead of passing it to the constructor\n",
      "WARNING:tensorflow:From C:\\Users\\Flori\\OneDrive\\Bureaublad\\Folders\\AMC\\Conferences\\Recomb2021\\models\\rPhyloConv\\rPhyloConv\\models.py:29: The name tf.keras.backend.get_session is deprecated. Please use tf.compat.v1.keras.backend.get_session instead.\n",
      "\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/2000\n",
      "182/182 - 1s - loss: 0.2519 - val_loss: 0.2506\n",
      "Epoch 2/2000\n",
      "182/182 - 0s - loss: 0.2485 - val_loss: 0.2506\n",
      "Epoch 3/2000\n",
      "182/182 - 0s - loss: 0.2460 - val_loss: 0.2504\n",
      "Epoch 4/2000\n",
      "182/182 - 0s - loss: 0.2437 - val_loss: 0.2503\n",
      "Epoch 5/2000\n",
      "182/182 - 0s - loss: 0.2414 - val_loss: 0.2505\n",
      "Epoch 6/2000\n",
      "182/182 - 0s - loss: 0.2393 - val_loss: 0.2507\n",
      "Epoch 7/2000\n",
      "182/182 - 0s - loss: 0.2367 - val_loss: 0.2511\n",
      "Epoch 8/2000\n",
      "182/182 - 0s - loss: 0.2369 - val_loss: 0.2516\n",
      "Epoch 9/2000\n",
      "182/182 - 0s - loss: 0.2339 - val_loss: 0.2522\n",
      "Epoch 10/2000\n",
      "182/182 - 0s - loss: 0.2291 - val_loss: 0.2525\n",
      "Epoch 11/2000\n",
      "182/182 - 0s - loss: 0.2271 - val_loss: 0.2530\n",
      "Epoch 12/2000\n",
      "182/182 - 0s - loss: 0.2250 - val_loss: 0.2534\n",
      "Epoch 13/2000\n",
      "182/182 - 0s - loss: 0.2209 - val_loss: 0.2539\n",
      "Epoch 14/2000\n",
      "182/182 - 0s - loss: 0.2176 - val_loss: 0.2545\n",
      "Epoch 15/2000\n",
      "182/182 - 0s - loss: 0.2164 - val_loss: 0.2546\n",
      "Epoch 16/2000\n",
      "182/182 - 0s - loss: 0.2111 - val_loss: 0.2548\n",
      "Epoch 17/2000\n",
      "182/182 - 0s - loss: 0.2054 - val_loss: 0.2561\n",
      "Epoch 18/2000\n",
      "182/182 - 0s - loss: 0.2023 - val_loss: 0.2575\n",
      "Epoch 19/2000\n",
      "182/182 - 0s - loss: 0.1958 - val_loss: 0.2585\n",
      "Epoch 20/2000\n",
      "182/182 - 0s - loss: 0.1984 - val_loss: 0.2585\n",
      "Epoch 21/2000\n",
      "182/182 - 0s - loss: 0.1869 - val_loss: 0.2593\n",
      "Epoch 22/2000\n",
      "182/182 - 0s - loss: 0.1838 - val_loss: 0.2611\n",
      "Epoch 23/2000\n",
      "182/182 - 0s - loss: 0.1838 - val_loss: 0.2624\n",
      "Epoch 24/2000\n",
      "182/182 - 0s - loss: 0.1734 - val_loss: 0.2633\n",
      "Epoch 25/2000\n",
      "182/182 - 0s - loss: 0.1709 - val_loss: 0.2647\n",
      "Epoch 26/2000\n",
      "182/182 - 0s - loss: 0.1659 - val_loss: 0.2665\n",
      "Epoch 27/2000\n",
      "182/182 - 0s - loss: 0.1611 - val_loss: 0.2674\n",
      "Epoch 28/2000\n",
      "182/182 - 0s - loss: 0.1525 - val_loss: 0.2685\n",
      "Epoch 29/2000\n",
      "182/182 - 0s - loss: 0.1504 - val_loss: 0.2703\n",
      "Epoch 30/2000\n",
      "182/182 - 0s - loss: 0.1499 - val_loss: 0.2720\n",
      "Epoch 31/2000\n",
      "182/182 - 0s - loss: 0.1442 - val_loss: 0.2734\n",
      "Epoch 32/2000\n",
      "182/182 - 0s - loss: 0.1391 - val_loss: 0.2744\n",
      "Epoch 33/2000\n",
      "182/182 - 0s - loss: 0.1357 - val_loss: 0.2763\n",
      "Epoch 34/2000\n",
      "182/182 - 0s - loss: 0.1293 - val_loss: 0.2793\n",
      "Epoch 35/2000\n",
      "182/182 - 0s - loss: 0.1243 - val_loss: 0.2802\n",
      "Epoch 36/2000\n",
      "182/182 - 0s - loss: 0.1209 - val_loss: 0.2815\n",
      "Epoch 37/2000\n",
      "182/182 - 0s - loss: 0.1165 - val_loss: 0.2835\n",
      "Epoch 38/2000\n",
      "182/182 - 0s - loss: 0.1141 - val_loss: 0.2834\n",
      "Epoch 39/2000\n",
      "182/182 - 0s - loss: 0.1139 - val_loss: 0.2847\n",
      "Epoch 40/2000\n",
      "182/182 - 0s - loss: 0.1047 - val_loss: 0.2882\n",
      "Epoch 41/2000\n",
      "182/182 - 0s - loss: 0.1063 - val_loss: 0.2906\n",
      "Epoch 42/2000\n",
      "182/182 - 0s - loss: 0.1047 - val_loss: 0.2886\n",
      "Epoch 43/2000\n",
      "182/182 - 0s - loss: 0.1005 - val_loss: 0.2919\n",
      "Epoch 44/2000\n",
      "182/182 - 0s - loss: 0.0995 - val_loss: 0.2940\n",
      "Evaluation:\n",
      "\n",
      "MSE: 0.29396851588811335\n",
      "AUC: 0.46313799621928164\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning cross validation for candidate number 1\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Total size of the training set: 182\n",
      "Total size of the validation set: 46\n",
      "Class frequencies in the training set: [0.5 0.5]\n",
      "Class frequencies in the validation set: [0.5 0.5]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning the tree building procedure\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Fitting candidate number 2 in shuffle 1 with parameters\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/2000\n",
      "182/182 - 1s - loss: 0.2523 - val_loss: 0.2498\n",
      "Epoch 2/2000\n",
      "182/182 - 0s - loss: 0.2488 - val_loss: 0.2498\n",
      "Epoch 3/2000\n",
      "182/182 - 0s - loss: 0.2468 - val_loss: 0.2499\n",
      "Epoch 4/2000\n",
      "182/182 - 0s - loss: 0.2444 - val_loss: 0.2500\n",
      "Epoch 5/2000\n",
      "182/182 - 0s - loss: 0.2426 - val_loss: 0.2502\n",
      "Epoch 6/2000\n",
      "182/182 - 0s - loss: 0.2415 - val_loss: 0.2504\n",
      "Epoch 7/2000\n",
      "182/182 - 0s - loss: 0.2386 - val_loss: 0.2506\n",
      "Epoch 8/2000\n",
      "182/182 - 0s - loss: 0.2370 - val_loss: 0.2509\n",
      "Epoch 9/2000\n",
      "182/182 - 0s - loss: 0.2340 - val_loss: 0.2513\n",
      "Epoch 10/2000\n",
      "182/182 - 0s - loss: 0.2308 - val_loss: 0.2517\n",
      "Epoch 11/2000\n",
      "182/182 - 0s - loss: 0.2285 - val_loss: 0.2523\n",
      "Epoch 12/2000\n",
      "182/182 - 0s - loss: 0.2239 - val_loss: 0.2529\n",
      "Epoch 13/2000\n",
      "182/182 - 0s - loss: 0.2194 - val_loss: 0.2540\n",
      "Epoch 14/2000\n",
      "182/182 - 0s - loss: 0.2202 - val_loss: 0.2552\n",
      "Epoch 15/2000\n",
      "182/182 - 0s - loss: 0.2151 - val_loss: 0.2560\n",
      "Epoch 16/2000\n",
      "182/182 - 0s - loss: 0.2107 - val_loss: 0.2565\n",
      "Epoch 17/2000\n",
      "182/182 - 0s - loss: 0.2059 - val_loss: 0.2577\n",
      "Epoch 18/2000\n",
      "182/182 - 0s - loss: 0.2048 - val_loss: 0.2594\n",
      "Epoch 19/2000\n",
      "182/182 - 0s - loss: 0.1964 - val_loss: 0.2611\n",
      "Epoch 20/2000\n",
      "182/182 - 0s - loss: 0.1889 - val_loss: 0.2632\n",
      "Epoch 21/2000\n",
      "182/182 - 0s - loss: 0.1891 - val_loss: 0.2645\n",
      "Epoch 22/2000\n",
      "182/182 - 0s - loss: 0.1816 - val_loss: 0.2660\n",
      "Epoch 23/2000\n",
      "182/182 - 0s - loss: 0.1809 - val_loss: 0.2682\n",
      "Epoch 24/2000\n",
      "182/182 - 0s - loss: 0.1717 - val_loss: 0.2705\n",
      "Epoch 25/2000\n",
      "182/182 - 0s - loss: 0.1737 - val_loss: 0.2723\n",
      "Epoch 26/2000\n",
      "182/182 - 0s - loss: 0.1610 - val_loss: 0.2745\n",
      "Epoch 27/2000\n",
      "182/182 - 0s - loss: 0.1588 - val_loss: 0.2774\n",
      "Epoch 28/2000\n",
      "182/182 - 0s - loss: 0.1492 - val_loss: 0.2801\n",
      "Epoch 29/2000\n",
      "182/182 - 0s - loss: 0.1475 - val_loss: 0.2828\n",
      "Epoch 30/2000\n",
      "182/182 - 0s - loss: 0.1416 - val_loss: 0.2856\n",
      "Epoch 31/2000\n",
      "182/182 - 0s - loss: 0.1399 - val_loss: 0.2883\n",
      "Epoch 32/2000\n",
      "182/182 - 0s - loss: 0.1310 - val_loss: 0.2910\n",
      "Epoch 33/2000\n",
      "182/182 - 0s - loss: 0.1259 - val_loss: 0.2949\n",
      "Epoch 34/2000\n",
      "182/182 - 0s - loss: 0.1253 - val_loss: 0.2975\n",
      "Epoch 35/2000\n",
      "182/182 - 0s - loss: 0.1222 - val_loss: 0.2986\n",
      "Epoch 36/2000\n",
      "182/182 - 0s - loss: 0.1179 - val_loss: 0.3019\n",
      "Epoch 37/2000\n",
      "182/182 - 0s - loss: 0.1154 - val_loss: 0.3054\n",
      "Epoch 38/2000\n",
      "182/182 - 0s - loss: 0.1132 - val_loss: 0.3085\n",
      "Epoch 39/2000\n",
      "182/182 - 0s - loss: 0.1097 - val_loss: 0.3101\n",
      "Epoch 40/2000\n",
      "182/182 - 0s - loss: 0.1022 - val_loss: 0.3134\n",
      "Epoch 41/2000\n",
      "182/182 - 0s - loss: 0.1035 - val_loss: 0.3173\n",
      "Epoch 42/2000\n",
      "182/182 - 0s - loss: 0.1010 - val_loss: 0.3193\n",
      "Evaluation:\n",
      "\n",
      "MSE: 0.3192681335534121\n",
      "AUC: 0.3610586011342155\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning cross validation for candidate number 2\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Total size of the training set: 182\n",
      "Total size of the validation set: 46\n",
      "Class frequencies in the training set: [0.5 0.5]\n",
      "Class frequencies in the validation set: [0.5 0.5]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning the tree building procedure\n",
      "----------------------------------------------------------------\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting candidate number 3 in shuffle 1 with parameters\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "Train on 182 samples, validate on 46 samples\n",
      "Epoch 1/2000\n",
      "182/182 - 1s - loss: 0.2495 - val_loss: 0.2550\n",
      "Epoch 2/2000\n",
      "182/182 - 0s - loss: 0.2451 - val_loss: 0.2547\n",
      "Epoch 3/2000\n",
      "182/182 - 0s - loss: 0.2393 - val_loss: 0.2548\n",
      "Epoch 4/2000\n",
      "182/182 - 0s - loss: 0.2366 - val_loss: 0.2550\n",
      "Epoch 5/2000\n",
      "182/182 - 0s - loss: 0.2353 - val_loss: 0.2556\n",
      "Epoch 6/2000\n",
      "182/182 - 0s - loss: 0.2287 - val_loss: 0.2561\n",
      "Epoch 7/2000\n",
      "182/182 - 0s - loss: 0.2311 - val_loss: 0.2560\n",
      "Epoch 8/2000\n",
      "182/182 - 0s - loss: 0.2248 - val_loss: 0.2558\n",
      "Epoch 9/2000\n",
      "182/182 - 0s - loss: 0.2181 - val_loss: 0.2552\n",
      "Epoch 10/2000\n",
      "182/182 - 0s - loss: 0.2131 - val_loss: 0.2549\n",
      "Epoch 11/2000\n",
      "182/182 - 0s - loss: 0.2109 - val_loss: 0.2551\n",
      "Epoch 12/2000\n",
      "182/182 - 0s - loss: 0.2058 - val_loss: 0.2551\n",
      "Epoch 13/2000\n",
      "182/182 - 0s - loss: 0.2003 - val_loss: 0.2555\n",
      "Epoch 14/2000\n",
      "182/182 - 0s - loss: 0.1986 - val_loss: 0.2555\n",
      "Epoch 15/2000\n",
      "182/182 - 0s - loss: 0.1871 - val_loss: 0.2557\n",
      "Epoch 16/2000\n",
      "182/182 - 0s - loss: 0.1834 - val_loss: 0.2559\n",
      "Epoch 17/2000\n",
      "182/182 - 0s - loss: 0.1809 - val_loss: 0.2565\n",
      "Epoch 18/2000\n",
      "182/182 - 0s - loss: 0.1698 - val_loss: 0.2569\n",
      "Epoch 19/2000\n",
      "182/182 - 0s - loss: 0.1788 - val_loss: 0.2567\n",
      "Epoch 20/2000\n",
      "182/182 - 0s - loss: 0.1647 - val_loss: 0.2563\n",
      "Epoch 21/2000\n",
      "182/182 - 0s - loss: 0.1638 - val_loss: 0.2564\n",
      "Epoch 22/2000\n",
      "182/182 - 0s - loss: 0.1581 - val_loss: 0.2559\n",
      "Epoch 23/2000\n",
      "182/182 - 0s - loss: 0.1542 - val_loss: 0.2561\n",
      "Epoch 24/2000\n",
      "182/182 - 0s - loss: 0.1486 - val_loss: 0.2565\n",
      "Epoch 25/2000\n",
      "182/182 - 0s - loss: 0.1525 - val_loss: 0.2564\n",
      "Epoch 26/2000\n",
      "182/182 - 0s - loss: 0.1462 - val_loss: 0.2566\n",
      "Epoch 27/2000\n",
      "182/182 - 0s - loss: 0.1348 - val_loss: 0.2577\n",
      "Epoch 28/2000\n",
      "182/182 - 0s - loss: 0.1315 - val_loss: 0.2583\n",
      "Epoch 29/2000\n",
      "182/182 - 0s - loss: 0.1310 - val_loss: 0.2590\n",
      "Epoch 30/2000\n",
      "182/182 - 0s - loss: 0.1233 - val_loss: 0.2597\n",
      "Epoch 31/2000\n",
      "182/182 - 0s - loss: 0.1233 - val_loss: 0.2603\n",
      "Epoch 32/2000\n",
      "182/182 - 0s - loss: 0.1191 - val_loss: 0.2606\n",
      "Epoch 33/2000\n",
      "182/182 - 0s - loss: 0.1141 - val_loss: 0.2611\n",
      "Epoch 34/2000\n",
      "182/182 - 0s - loss: 0.1152 - val_loss: 0.2615\n",
      "Epoch 35/2000\n",
      "182/182 - 0s - loss: 0.1086 - val_loss: 0.2620\n",
      "Epoch 36/2000\n",
      "182/182 - 0s - loss: 0.1092 - val_loss: 0.2622\n",
      "Epoch 37/2000\n",
      "182/182 - 0s - loss: 0.1050 - val_loss: 0.2621\n",
      "Epoch 38/2000\n",
      "182/182 - 0s - loss: 0.0992 - val_loss: 0.2637\n",
      "Epoch 39/2000\n",
      "182/182 - 0s - loss: 0.0961 - val_loss: 0.2646\n",
      "Epoch 40/2000\n",
      "182/182 - 0s - loss: 0.0905 - val_loss: 0.2651\n",
      "Epoch 41/2000\n",
      "182/182 - 0s - loss: 0.0963 - val_loss: 0.2651\n",
      "Epoch 42/2000\n",
      "182/182 - 0s - loss: 0.0937 - val_loss: 0.2650\n",
      "Evaluation:\n",
      "\n",
      "MSE: 0.26500072902766025\n",
      "AUC: 0.5708884688090737\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning cross validation for candidate number 3\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Total size of the training set: 183\n",
      "Total size of the validation set: 45\n",
      "Class frequencies in the training set: [0.49726776 0.50273224]\n",
      "Class frequencies in the validation set: [0.51111111 0.48888889]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning the tree building procedure\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Fitting candidate number 4 in shuffle 1 with parameters\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "Train on 183 samples, validate on 45 samples\n",
      "Epoch 1/2000\n",
      "183/183 - 1s - loss: 0.2511 - val_loss: 0.2496\n",
      "Epoch 2/2000\n",
      "183/183 - 0s - loss: 0.2491 - val_loss: 0.2499\n",
      "Epoch 3/2000\n",
      "183/183 - 0s - loss: 0.2473 - val_loss: 0.2505\n",
      "Epoch 4/2000\n",
      "183/183 - 0s - loss: 0.2473 - val_loss: 0.2505\n",
      "Epoch 5/2000\n",
      "183/183 - 0s - loss: 0.2433 - val_loss: 0.2505\n",
      "Epoch 6/2000\n",
      "183/183 - 0s - loss: 0.2436 - val_loss: 0.2507\n",
      "Epoch 7/2000\n",
      "183/183 - 0s - loss: 0.2413 - val_loss: 0.2506\n",
      "Epoch 8/2000\n",
      "183/183 - 0s - loss: 0.2392 - val_loss: 0.2507\n",
      "Epoch 9/2000\n",
      "183/183 - 0s - loss: 0.2378 - val_loss: 0.2508\n",
      "Epoch 10/2000\n",
      "183/183 - 0s - loss: 0.2355 - val_loss: 0.2511\n",
      "Epoch 11/2000\n",
      "183/183 - 0s - loss: 0.2325 - val_loss: 0.2515\n",
      "Epoch 12/2000\n",
      "183/183 - 0s - loss: 0.2316 - val_loss: 0.2518\n",
      "Epoch 13/2000\n",
      "183/183 - 0s - loss: 0.2287 - val_loss: 0.2523\n",
      "Epoch 14/2000\n",
      "183/183 - 0s - loss: 0.2248 - val_loss: 0.2529\n",
      "Epoch 15/2000\n",
      "183/183 - 0s - loss: 0.2223 - val_loss: 0.2533\n",
      "Epoch 16/2000\n",
      "183/183 - 0s - loss: 0.2194 - val_loss: 0.2539\n",
      "Epoch 17/2000\n",
      "183/183 - 0s - loss: 0.2159 - val_loss: 0.2546\n",
      "Epoch 18/2000\n",
      "183/183 - 0s - loss: 0.2149 - val_loss: 0.2555\n",
      "Epoch 19/2000\n",
      "183/183 - 0s - loss: 0.2093 - val_loss: 0.2563\n",
      "Epoch 20/2000\n",
      "183/183 - 0s - loss: 0.2069 - val_loss: 0.2571\n",
      "Epoch 21/2000\n",
      "183/183 - 0s - loss: 0.2028 - val_loss: 0.2584\n",
      "Epoch 22/2000\n",
      "183/183 - 0s - loss: 0.1969 - val_loss: 0.2598\n",
      "Epoch 23/2000\n",
      "183/183 - 0s - loss: 0.1935 - val_loss: 0.2603\n",
      "Epoch 24/2000\n",
      "183/183 - 0s - loss: 0.1862 - val_loss: 0.2613\n",
      "Epoch 25/2000\n",
      "183/183 - 0s - loss: 0.1818 - val_loss: 0.2630\n",
      "Epoch 26/2000\n",
      "183/183 - 0s - loss: 0.1800 - val_loss: 0.2640\n",
      "Epoch 27/2000\n",
      "183/183 - 0s - loss: 0.1736 - val_loss: 0.2653\n",
      "Epoch 28/2000\n",
      "183/183 - 0s - loss: 0.1734 - val_loss: 0.2666\n",
      "Epoch 29/2000\n",
      "183/183 - 0s - loss: 0.1645 - val_loss: 0.2681\n",
      "Epoch 30/2000\n",
      "183/183 - 0s - loss: 0.1632 - val_loss: 0.2698\n",
      "Epoch 31/2000\n",
      "183/183 - 0s - loss: 0.1549 - val_loss: 0.2717\n",
      "Epoch 32/2000\n",
      "183/183 - 0s - loss: 0.1553 - val_loss: 0.2739\n",
      "Epoch 33/2000\n",
      "183/183 - 0s - loss: 0.1537 - val_loss: 0.2753\n",
      "Epoch 34/2000\n",
      "183/183 - 0s - loss: 0.1431 - val_loss: 0.2769\n",
      "Epoch 35/2000\n",
      "183/183 - 0s - loss: 0.1366 - val_loss: 0.2791\n",
      "Epoch 36/2000\n",
      "183/183 - 0s - loss: 0.1371 - val_loss: 0.2810\n",
      "Epoch 37/2000\n",
      "183/183 - 0s - loss: 0.1370 - val_loss: 0.2820\n",
      "Epoch 38/2000\n",
      "183/183 - 0s - loss: 0.1333 - val_loss: 0.2834\n",
      "Epoch 39/2000\n",
      "183/183 - 0s - loss: 0.1314 - val_loss: 0.2864\n",
      "Epoch 40/2000\n",
      "183/183 - 0s - loss: 0.1225 - val_loss: 0.2891\n",
      "Epoch 41/2000\n",
      "183/183 - 0s - loss: 0.1213 - val_loss: 0.2911\n",
      "Evaluation:\n",
      "\n",
      "MSE: 0.29114564206150745\n",
      "AUC: 0.4347826086956521\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning cross validation for candidate number 4\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Total size of the training set: 183\n",
      "Total size of the validation set: 45\n",
      "Class frequencies in the training set: [0.50273224 0.49726776]\n",
      "Class frequencies in the validation set: [0.48888889 0.51111111]\n",
      "\n",
      "----------------------------------------------------------------\n",
      "Beginning the tree building procedure\n",
      "----------------------------------------------------------------\n",
      "\n",
      "Fitting candidate number 5 in shuffle 1 with parameters\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "Train on 183 samples, validate on 45 samples\n",
      "Epoch 1/2000\n",
      "183/183 - 1s - loss: 0.2524 - val_loss: 0.2493\n",
      "Epoch 2/2000\n",
      "183/183 - 0s - loss: 0.2493 - val_loss: 0.2494\n",
      "Epoch 3/2000\n",
      "183/183 - 0s - loss: 0.2484 - val_loss: 0.2491\n",
      "Epoch 4/2000\n",
      "183/183 - 0s - loss: 0.2464 - val_loss: 0.2485\n",
      "Epoch 5/2000\n",
      "183/183 - 0s - loss: 0.2463 - val_loss: 0.2479\n",
      "Epoch 6/2000\n",
      "183/183 - 0s - loss: 0.2431 - val_loss: 0.2476\n",
      "Epoch 7/2000\n",
      "183/183 - 0s - loss: 0.2425 - val_loss: 0.2473\n",
      "Epoch 8/2000\n",
      "183/183 - 0s - loss: 0.2394 - val_loss: 0.2468\n",
      "Epoch 9/2000\n",
      "183/183 - 0s - loss: 0.2378 - val_loss: 0.2462\n",
      "Epoch 10/2000\n",
      "183/183 - 0s - loss: 0.2374 - val_loss: 0.2455\n",
      "Epoch 11/2000\n",
      "183/183 - 0s - loss: 0.2353 - val_loss: 0.2451\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 12/2000\n",
      "183/183 - 0s - loss: 0.2333 - val_loss: 0.2449\n",
      "Epoch 13/2000\n",
      "183/183 - 0s - loss: 0.2301 - val_loss: 0.2442\n",
      "Epoch 14/2000\n",
      "183/183 - 0s - loss: 0.2307 - val_loss: 0.2436\n",
      "Epoch 15/2000\n",
      "183/183 - 0s - loss: 0.2278 - val_loss: 0.2432\n",
      "Epoch 16/2000\n",
      "183/183 - 0s - loss: 0.2249 - val_loss: 0.2428\n",
      "Epoch 17/2000\n",
      "183/183 - 0s - loss: 0.2217 - val_loss: 0.2423\n",
      "Epoch 18/2000\n",
      "183/183 - 0s - loss: 0.2181 - val_loss: 0.2418\n",
      "Epoch 19/2000\n",
      "183/183 - 0s - loss: 0.2138 - val_loss: 0.2408\n",
      "Epoch 20/2000\n",
      "183/183 - 0s - loss: 0.2100 - val_loss: 0.2400\n",
      "Epoch 21/2000\n",
      "183/183 - 0s - loss: 0.2077 - val_loss: 0.2392\n",
      "Epoch 22/2000\n",
      "183/183 - 0s - loss: 0.2039 - val_loss: 0.2386\n",
      "Epoch 23/2000\n",
      "183/183 - 0s - loss: 0.1985 - val_loss: 0.2381\n",
      "Epoch 24/2000\n",
      "183/183 - 0s - loss: 0.2003 - val_loss: 0.2378\n",
      "Epoch 25/2000\n",
      "183/183 - 0s - loss: 0.1984 - val_loss: 0.2381\n",
      "Epoch 26/2000\n",
      "183/183 - 0s - loss: 0.1924 - val_loss: 0.2377\n",
      "Epoch 27/2000\n",
      "183/183 - 0s - loss: 0.1885 - val_loss: 0.2375\n",
      "Epoch 28/2000\n",
      "183/183 - 0s - loss: 0.1836 - val_loss: 0.2370\n",
      "Epoch 29/2000\n",
      "183/183 - 0s - loss: 0.1818 - val_loss: 0.2363\n",
      "Epoch 30/2000\n",
      "183/183 - 0s - loss: 0.1789 - val_loss: 0.2355\n",
      "Epoch 31/2000\n",
      "183/183 - 0s - loss: 0.1701 - val_loss: 0.2355\n",
      "Epoch 32/2000\n",
      "183/183 - 0s - loss: 0.1673 - val_loss: 0.2368\n",
      "Epoch 33/2000\n",
      "183/183 - 0s - loss: 0.1631 - val_loss: 0.2377\n",
      "Epoch 34/2000\n",
      "183/183 - 0s - loss: 0.1657 - val_loss: 0.2368\n",
      "Epoch 35/2000\n",
      "183/183 - 0s - loss: 0.1561 - val_loss: 0.2369\n",
      "Epoch 36/2000\n",
      "183/183 - 0s - loss: 0.1565 - val_loss: 0.2379\n",
      "Epoch 37/2000\n",
      "183/183 - 0s - loss: 0.1469 - val_loss: 0.2382\n",
      "Epoch 38/2000\n",
      "183/183 - 0s - loss: 0.1441 - val_loss: 0.2371\n",
      "Epoch 39/2000\n",
      "183/183 - 0s - loss: 0.1442 - val_loss: 0.2377\n",
      "Epoch 40/2000\n",
      "183/183 - 0s - loss: 0.1392 - val_loss: 0.2384\n",
      "Epoch 41/2000\n",
      "183/183 - 0s - loss: 0.1330 - val_loss: 0.2403\n",
      "Epoch 42/2000\n",
      "183/183 - 0s - loss: 0.1329 - val_loss: 0.2421\n",
      "Epoch 43/2000\n",
      "183/183 - 0s - loss: 0.1282 - val_loss: 0.2415\n",
      "Epoch 44/2000\n",
      "183/183 - 0s - loss: 0.1236 - val_loss: 0.2401\n",
      "Epoch 45/2000\n",
      "183/183 - 0s - loss: 0.1205 - val_loss: 0.2404\n",
      "Epoch 46/2000\n",
      "183/183 - 0s - loss: 0.1207 - val_loss: 0.2426\n",
      "Epoch 47/2000\n",
      "183/183 - 0s - loss: 0.1178 - val_loss: 0.2445\n",
      "Epoch 48/2000\n",
      "183/183 - 0s - loss: 0.1102 - val_loss: 0.2467\n",
      "Epoch 49/2000\n",
      "183/183 - 0s - loss: 0.1080 - val_loss: 0.2454\n",
      "Epoch 50/2000\n",
      "183/183 - 0s - loss: 0.1091 - val_loss: 0.2441\n",
      "Epoch 51/2000\n",
      "183/183 - 0s - loss: 0.1012 - val_loss: 0.2470\n",
      "Epoch 52/2000\n",
      "183/183 - 0s - loss: 0.1009 - val_loss: 0.2502\n",
      "Epoch 53/2000\n",
      "183/183 - 0s - loss: 0.0975 - val_loss: 0.2505\n",
      "Epoch 54/2000\n",
      "183/183 - 0s - loss: 0.0927 - val_loss: 0.2506\n",
      "Epoch 55/2000\n",
      "183/183 - 0s - loss: 0.0907 - val_loss: 0.2506\n",
      "Epoch 56/2000\n",
      "183/183 - 0s - loss: 0.0903 - val_loss: 0.2495\n",
      "Epoch 57/2000\n",
      "183/183 - 0s - loss: 0.0870 - val_loss: 0.2510\n",
      "Epoch 58/2000\n",
      "183/183 - 0s - loss: 0.0906 - val_loss: 0.2556\n",
      "Epoch 59/2000\n",
      "183/183 - 0s - loss: 0.0843 - val_loss: 0.2562\n",
      "Epoch 60/2000\n",
      "183/183 - 0s - loss: 0.0869 - val_loss: 0.2548\n",
      "Epoch 61/2000\n",
      "183/183 - 0s - loss: 0.0767 - val_loss: 0.2544\n",
      "Epoch 62/2000\n",
      "183/183 - 0s - loss: 0.0786 - val_loss: 0.2581\n",
      "Epoch 63/2000\n",
      "183/183 - 0s - loss: 0.0764 - val_loss: 0.2589\n",
      "Epoch 64/2000\n",
      "183/183 - 0s - loss: 0.0782 - val_loss: 0.2590\n",
      "Epoch 65/2000\n",
      "183/183 - 0s - loss: 0.0762 - val_loss: 0.2602\n",
      "Epoch 66/2000\n",
      "183/183 - 0s - loss: 0.0708 - val_loss: 0.2615\n",
      "Epoch 67/2000\n",
      "183/183 - 0s - loss: 0.0706 - val_loss: 0.2629\n",
      "Epoch 68/2000\n",
      "183/183 - 0s - loss: 0.0669 - val_loss: 0.2621\n",
      "Epoch 69/2000\n",
      "183/183 - 0s - loss: 0.0681 - val_loss: 0.2650\n",
      "Epoch 70/2000\n",
      "183/183 - 0s - loss: 0.0657 - val_loss: 0.2668\n",
      "Evaluation:\n",
      "\n",
      "MSE: 0.2668442079466514\n",
      "AUC: 0.6225296442687747\n",
      "\n",
      "                                                      CV_1_GS_1  \\\n",
      "AUC                                                    0.463138   \n",
      "Weighted MSE                                           0.293969   \n",
      "Params        {'activation': 'elu', 'batch_size': 64, 'callb...   \n",
      "Features      [Unnamed: 0, Zotu2211, Zotu1580, Zotu19827, Zo...   \n",
      "\n",
      "                                                      CV_2_GS_1  \\\n",
      "AUC                                                    0.361059   \n",
      "Weighted MSE                                           0.319268   \n",
      "Params        {'activation': 'elu', 'batch_size': 64, 'callb...   \n",
      "Features      [Unnamed: 0, Zotu2211, Zotu1580, Zotu19827, Zo...   \n",
      "\n",
      "                                                      CV_3_GS_1  \\\n",
      "AUC                                                    0.570888   \n",
      "Weighted MSE                                           0.265001   \n",
      "Params        {'activation': 'elu', 'batch_size': 64, 'callb...   \n",
      "Features      [Unnamed: 0, Zotu2211, Zotu1580, Zotu19827, Zo...   \n",
      "\n",
      "                                                      CV_4_GS_1  \\\n",
      "AUC                                                    0.434783   \n",
      "Weighted MSE                                           0.291146   \n",
      "Params        {'activation': 'elu', 'batch_size': 64, 'callb...   \n",
      "Features      [Unnamed: 0, Zotu2211, Zotu1580, Zotu19827, Zo...   \n",
      "\n",
      "                                                      CV_5_GS_1  \n",
      "AUC                                                     0.62253  \n",
      "Weighted MSE                                           0.266844  \n",
      "Params        {'activation': 'elu', 'batch_size': 64, 'callb...  \n",
      "Features      [Unnamed: 0, Zotu2211, Zotu1580, Zotu19827, Zo...  \n",
      "Directory already exists\n",
      "Reftting on the entire training set with the best found parameters\n",
      "\n",
      "Best found parameters:\n",
      "\n",
      "{'activation': 'elu', 'batch_size': 64, 'callbacks': [<tensorflow.python.keras.callbacks.EarlyStopping object at 0x0000019C066CB4C8>], 'dropout': 0.3, 'epochs': 2000, 'filters': 10, 'input_shape': None, 'kernel_size': (3, 9), 'learning_rate': 0.001, 'loss': 'mse', 'n_classes': 2, 'n_layers': 1, 'pool_size': (2, 2), 'verbose': 2}\n",
      "Samples X_train: 205\n",
      "Samples X_test: 58\n",
      "Labels in y_train: [103. 102.]\n",
      "\n",
      "Rebuilt model and thus reinitialized\n",
      "Train on 205 samples, validate on 23 samples\n",
      "Epoch 1/2000\n",
      "205/205 - 1s - loss: 0.2614 - val_loss: 0.2574\n",
      "Epoch 2/2000\n",
      "205/205 - 0s - loss: 0.2478 - val_loss: 0.2568\n",
      "Epoch 3/2000\n",
      "205/205 - 0s - loss: 0.2414 - val_loss: 0.2563\n",
      "Epoch 4/2000\n",
      "205/205 - 0s - loss: 0.2384 - val_loss: 0.2566\n",
      "Epoch 5/2000\n",
      "205/205 - 0s - loss: 0.2315 - val_loss: 0.2570\n",
      "Epoch 6/2000\n",
      "205/205 - 0s - loss: 0.2258 - val_loss: 0.2568\n",
      "Epoch 7/2000\n",
      "205/205 - 0s - loss: 0.2164 - val_loss: 0.2564\n",
      "Epoch 8/2000\n",
      "205/205 - 0s - loss: 0.2105 - val_loss: 0.2558\n",
      "Epoch 9/2000\n",
      "205/205 - 0s - loss: 0.2083 - val_loss: 0.2558\n",
      "Epoch 10/2000\n",
      "205/205 - 0s - loss: 0.1991 - val_loss: 0.2575\n",
      "Epoch 11/2000\n",
      "205/205 - 0s - loss: 0.1951 - val_loss: 0.2598\n",
      "Epoch 12/2000\n",
      "205/205 - 0s - loss: 0.1859 - val_loss: 0.2640\n",
      "Epoch 13/2000\n",
      "205/205 - 0s - loss: 0.1843 - val_loss: 0.2670\n",
      "Epoch 14/2000\n",
      "205/205 - 0s - loss: 0.1783 - val_loss: 0.2702\n",
      "Epoch 15/2000\n",
      "205/205 - 0s - loss: 0.1720 - val_loss: 0.2729\n",
      "Epoch 16/2000\n",
      "205/205 - 0s - loss: 0.1600 - val_loss: 0.2762\n",
      "Epoch 17/2000\n",
      "205/205 - 0s - loss: 0.1572 - val_loss: 0.2790\n",
      "Epoch 18/2000\n",
      "205/205 - 0s - loss: 0.1521 - val_loss: 0.2823\n",
      "Epoch 19/2000\n",
      "205/205 - 0s - loss: 0.1466 - val_loss: 0.2860\n",
      "Epoch 20/2000\n",
      "205/205 - 0s - loss: 0.1452 - val_loss: 0.2903\n",
      "Epoch 21/2000\n",
      "205/205 - 0s - loss: 0.1347 - val_loss: 0.2923\n",
      "Epoch 22/2000\n",
      "205/205 - 0s - loss: 0.1277 - val_loss: 0.2937\n",
      "Epoch 23/2000\n",
      "205/205 - 0s - loss: 0.1232 - val_loss: 0.2970\n",
      "Epoch 24/2000\n",
      "205/205 - 0s - loss: 0.1184 - val_loss: 0.3013\n",
      "Epoch 25/2000\n",
      "205/205 - 0s - loss: 0.1206 - val_loss: 0.3056\n",
      "Epoch 26/2000\n",
      "205/205 - 0s - loss: 0.1119 - val_loss: 0.3071\n",
      "Epoch 27/2000\n",
      "205/205 - 0s - loss: 0.1043 - val_loss: 0.3093\n",
      "Epoch 28/2000\n",
      "205/205 - 0s - loss: 0.1068 - val_loss: 0.3099\n",
      "Epoch 29/2000\n",
      "205/205 - 0s - loss: 0.1017 - val_loss: 0.3073\n",
      "Epoch 30/2000\n",
      "205/205 - 0s - loss: 0.0968 - val_loss: 0.3082\n",
      "Epoch 31/2000\n",
      "205/205 - 0s - loss: 0.0916 - val_loss: 0.3138\n",
      "Epoch 32/2000\n",
      "205/205 - 0s - loss: 0.0934 - val_loss: 0.3226\n",
      "Epoch 33/2000\n",
      "205/205 - 0s - loss: 0.0840 - val_loss: 0.3343\n",
      "Epoch 34/2000\n",
      "205/205 - 0s - loss: 0.0865 - val_loss: 0.3351\n",
      "Epoch 35/2000\n",
      "205/205 - 0s - loss: 0.0885 - val_loss: 0.3337\n",
      "Epoch 36/2000\n",
      "205/205 - 0s - loss: 0.0776 - val_loss: 0.3367\n",
      "Epoch 37/2000\n",
      "205/205 - 0s - loss: 0.0697 - val_loss: 0.3382\n",
      "Epoch 38/2000\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "205/205 - 0s - loss: 0.0713 - val_loss: 0.3411\n",
      "Epoch 39/2000\n",
      "205/205 - 0s - loss: 0.0673 - val_loss: 0.3376\n",
      "Epoch 40/2000\n",
      "205/205 - 0s - loss: 0.0717 - val_loss: 0.3382\n",
      "Epoch 41/2000\n",
      "205/205 - 0s - loss: 0.0671 - val_loss: 0.3468\n",
      "Epoch 42/2000\n",
      "205/205 - 0s - loss: 0.0623 - val_loss: 0.3575\n",
      "Epoch 43/2000\n",
      "205/205 - 0s - loss: 0.0601 - val_loss: 0.3585\n",
      "Epoch 44/2000\n",
      "205/205 - 0s - loss: 0.0639 - val_loss: 0.3522\n",
      "Epoch 45/2000\n",
      "205/205 - 0s - loss: 0.0558 - val_loss: 0.3482\n",
      "Epoch 46/2000\n",
      "205/205 - 0s - loss: 0.0606 - val_loss: 0.3568\n",
      "Epoch 47/2000\n",
      "205/205 - 0s - loss: 0.0546 - val_loss: 0.3630\n",
      "Epoch 48/2000\n",
      "205/205 - 0s - loss: 0.0538 - val_loss: 0.3662\n",
      "Epoch 49/2000\n",
      "205/205 - 0s - loss: 0.0550 - val_loss: 0.3635\n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'interp' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-6-1a96ff03a7cf>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[0mlist_auc\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_roc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m     \u001b[0mtprs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0minterp\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mmean_fpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfpr\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mtpr\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m     \u001b[0mtprs\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m-\u001b[0m\u001b[1;36m1\u001b[0m\u001b[1;33m]\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;36m0\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;36m0.0\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m     \u001b[0maucs\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mappend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mauc_roc1\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mNameError\u001b[0m: name 'interp' is not defined"
     ]
    }
   ],
   "source": [
    "skf=StratifiedKFold(n_splits = n_cv_folds)\n",
    "\n",
    "param_grid = {\n",
    "    'input_shape': [None],\n",
    "    'n_layers': [1],\n",
    "    'filters': [10],\n",
    "    'kernel_size': [(3, 9)],\n",
    "    'pool_size': [(2, 2)],\n",
    "    'activation': ['elu'],\n",
    "    'n_classes': [2],\n",
    "    'learning_rate': [0.001],\n",
    "    'loss': ['mse'],\n",
    "    'dropout': [0.3],\n",
    "    'batch_size': [64],\n",
    "    'epochs': [2000],\n",
    "    'callbacks': [[EarlyStopping(patience=40)]],\n",
    "    'verbose': [2]\n",
    "}\n",
    "\n",
    "grid_size = 1\n",
    "for key, value in param_grid.items():\n",
    "    grid_size *= len(value)\n",
    "fit_keys = ['batch_size', 'epochs', 'callbacks', 'verbose']\n",
    "\n",
    "###############################################################\n",
    "# Starting stability selection loop\n",
    "###############################################################\n",
    "test_stat_df = pd.DataFrame(index=[\"AUC\", \"Weighted MSE\", \"Params\", \"Features\"], columns=[i+1 for i in range(n_shuffles)])\n",
    "shuffle_counter = 0\n",
    "\n",
    "print(X.shape)\n",
    "print(type(X))\n",
    "\n",
    "n_values = np.max(y) + 1\n",
    "labels_oh = np.eye(n_values)[y]\n",
    "\n",
    "for samples,test in StratShufSpl.split(X, y):\n",
    "    print(\"----------------------------------------------------------------\")\n",
    "    print(\"Beginning stability selection iteration {}\".format(shuffle_counter))\n",
    "    print(\"----------------------------------------------------------------\\n\")\n",
    "    shuffle_counter += 1\n",
    "    X_train, X_test = X.iloc[samples], X.iloc[test]\n",
    "    y_train, y_test=y[samples], y[test]\n",
    "\n",
    "    # Creating a dataframe for storing the results\n",
    "    cv_list = [\"CV_{}_GS_{}\".format(str(i+1), str(j+1)) for i in range(n_cv_folds) for j in range(len(ParameterGrid(param_grid)))]\n",
    "    stat_df = pd.DataFrame(index=[\"AUC\", \"Weighted MSE\", \"Params\", \"Features\"], columns=cv_list)\n",
    "\n",
    "    # Performing the grid search CV\n",
    "    n_candidates = n_cv_folds * grid_size\n",
    "    cv_fold = 0\n",
    "    candidate_counter = 0\n",
    "    print('Performing GridSearchCV for {} candidates\\n\\n'.format(n_candidates))\n",
    "    for train_index, test_index in skf.split(X_train, y_train):\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"Beginning cross validation for candidate number {}\".format(candidate_counter))\n",
    "        print(\"----------------------------------------------------------------\\n\")\n",
    "        #################################################################\n",
    "        # Select and format training and testing sets\n",
    "        #################################################################\n",
    "        cv_fold += 1\n",
    "        gs_it = 0\n",
    "\n",
    "        train_X, val_X = X_train.iloc[train_index], X_train.iloc[test_index]\n",
    "        train_index = samples[train_index]\n",
    "        test_index = samples[test_index]\n",
    "        train_y, val_y = labels_oh[train_index,:], labels_oh[test_index,:]\n",
    "        class_frequencies_train = np.sum(train_y, axis = 0)/len(train_y)\n",
    "        class_frequencies_val = np.sum(val_y, axis = 0)/len(val_y)\n",
    "        print('Total size of the training set: {}'.format(len(train_X)))\n",
    "        print('Total size of the validation set: {}'.format(len(val_X)))\n",
    "        print('Class frequencies in the training set: {}'.format(class_frequencies_train))\n",
    "        print('Class frequencies in the validation set: {}\\n'.format(class_frequencies_val))\n",
    "     \n",
    "        \n",
    "        # Build tree\n",
    "        print(\"----------------------------------------------------------------\")\n",
    "        print(\"Beginning the tree building procedure\")\n",
    "        print(\"----------------------------------------------------------------\\n\")\n",
    "\n",
    "        tree_builder = TreeBuilder(tree_path)\n",
    "        tree_builder = tree_builder.fit(train_X, train_y)\n",
    "        train_X = tree_builder.transform(train_X)\n",
    "        val_X = tree_builder.transform(val_X) \n",
    "\n",
    "        for g in ParameterGrid(param_grid):\n",
    "            candidate_counter += 1\n",
    "            print('Fitting candidate number {} in shuffle {} with parameters\\n'.format(candidate_counter, shuffle_counter))\n",
    "            print(g)\n",
    "            gs_it += 1\n",
    "            params = g.copy()\n",
    "            fit_params = {key: g.pop(key) for key in fit_keys}\n",
    "\n",
    "            num_train_samples = train_X.shape[0]\n",
    "            num_test_samples = val_X.shape[0]\n",
    "            tree_row = train_X.shape[1]\n",
    "            tree_col = train_X.shape[2]\n",
    "\n",
    "            g['input_shape'] = (tree_row, tree_col)\n",
    "        \n",
    "            fit_params['x'] = train_X\n",
    "            fit_params['y'] = train_y\n",
    "            fit_params['validation_data'] = (val_X, val_y)\n",
    "            \n",
    "            # Seting model parameters and fitting\n",
    "            model = build_model(**g)\n",
    "            model.fit(**fit_params)\n",
    "\n",
    "            # Evaluation\n",
    "            print('Evaluation:\\n')\n",
    "            val_preds = model.predict(val_X)\n",
    "            auc_score = roc_auc_score(val_y, val_preds)\n",
    "            mse = mean_squared_error(val_y, val_preds)\n",
    "            #mse, auc = model.evaluate(x = val_X, y = val_y, verbose = 0)\n",
    "            print('MSE: {}'.format(mse))\n",
    "            print('AUC: {}\\n'.format(auc_score))\n",
    "            \n",
    "            # Storing stats in dataframe\n",
    "            stat_df.loc[\"Weighted MSE\"][\"CV_{}_GS_{}\".format(cv_fold, gs_it)] = mse\n",
    "            stat_df.loc[\"AUC\"][\"CV_{}_GS_{}\".format(cv_fold, gs_it)] = auc_score\n",
    "            stat_df.loc[\"Params\"][\"CV_{}_GS_{}\".format(cv_fold, gs_it)] = params\n",
    "            stat_df.loc[\"Features\"][\"CV_{}_GS_{}\".format(cv_fold, gs_it)] = tree_builder.features\n",
    "\n",
    "            # Resetting model weights and clearing the session\n",
    "            tf.keras.backend.clear_session()\n",
    "\n",
    "\n",
    "    print(stat_df)\n",
    "    # End of GS_CV\n",
    "    # Find best params according to lowest weighted MSE\n",
    "    # Refit model on train + val with best params\n",
    "    # Report all scores on test\n",
    "    # Save in test_stat_df\n",
    "\n",
    "    # Saving the results\n",
    "    try:\n",
    "        os.mkdir('output_data')\n",
    "    except OSError as error:\n",
    "        print('Directory already exists')\n",
    "\n",
    "    stat_df.to_csv('output_data/validation_results_{}.csv'.format(shuffle_counter))\n",
    "\n",
    "\n",
    "    # Reftting on the entire training set with the best found parameters\n",
    "    print('Reftting on the entire training set with the best found parameters\\n')\n",
    "    tf.keras.backend.clear_session()\n",
    "    grouped_df, params = group_by_params(stat_df, num_combinations = grid_size)\n",
    "    grouped_df.to_csv('output_data/grouped_validation_results_{}.csv'.format(shuffle_counter))\n",
    "    best_score_index = np.argmin(list(grouped_df.loc['Weighted MSE']))\n",
    "    best_params = params[best_score_index]\n",
    "    print('Best found parameters:\\n')\n",
    "    print(best_params)\n",
    "    X_train = np.log(X_train + 1)\n",
    "    X_test = np.log(X_test + 1)\n",
    "    y_train, y_test = labels_oh[samples,:], labels_oh[test,:]\n",
    "\n",
    "    \n",
    "    # Build tree\n",
    "    tree_builder = TreeBuilder(tree_path)\n",
    "    tree_builder = tree_builder.fit(X_train, y_train)\n",
    "    X_train = tree_builder.transform(X_train)\n",
    "    X_test = tree_builder.transform(X_test) \n",
    "\n",
    "    num_train_samples = X_train.shape[0]\n",
    "    num_test_samples = X_test.shape[0]\n",
    "    tree_row = X_train.shape[1]\n",
    "    tree_col = X_train.shape[2]\n",
    "\n",
    "    fit_params = {key: best_params.pop(key) for key in fit_keys}\n",
    "\n",
    "    # Splitting the data in train and val for early stopping\n",
    "    X_train, X_val, y_train, y_val = train_test_split(X_train, y_train,\n",
    "                                                    stratify=y_train, \n",
    "                                                   test_size=0.1)\n",
    "    fit_params['x'] = X_train\n",
    "    fit_params['y'] = y_train\n",
    "    fit_params['validation_data'] = (X_val, y_val)\n",
    "    best_params['input_shape'] = (tree_row, tree_col)\n",
    "\n",
    "    print('Samples X_train: {}'.format(len(X_train)))\n",
    "    print('Samples X_test: {}'.format(len(X_test)))\n",
    "    print('Labels in y_train: {}\\n'.format(np.sum(y_train, axis = 0)))\n",
    "\n",
    "    #test_untrained_weights = model.get_weights().copy()\n",
    "    model = build_model(**best_params)\n",
    "    print('Rebuilt model and thus reinitialized')\n",
    "    model.fit(**fit_params)\n",
    "    \n",
    "    y_pred_test = model.predict(X_test)[:, 0]\n",
    "    y_test = y_test[:, 0]\n",
    "    np.save('test_preds.npy', y_pred_test)\n",
    "    np.save('test_y.npy', y_test)\n",
    "\n",
    "    ### ONLY FOR A TEST\n",
    "    np.save(\"X_train.npy\", X_train)\n",
    "    model.save(\"test_model\")\n",
    "\n",
    "    final_params = {**best_params, **fit_params}\n",
    "    del final_params['x']\n",
    "    del final_params['y']\n",
    "    del final_params['validation_data']\n",
    "\n",
    "    mse = model.evaluate(x = X_test, y = y_test, verbose = 0)\n",
    "    auc_score = roc_auc_score(y_test, y_pred_test)\n",
    "\n",
    "    test_stat_df.loc[\"Weighted MSE\"][shuffle_counter] = mse\n",
    "    test_stat_df.loc[\"AUC\"][shuffle_counter] = auc_score\n",
    "    test_stat_df.loc[\"Features\"][shuffle_counter] = tree_builder.features\n",
    "    test_stat_df.loc[\"Params\"][shuffle_counter] = final_params\n",
    "\n",
    "    # Storing the FPR, TPR and thresholds for creating an AUC plot\n",
    "    fpr, tpr, thresholds = roc_curve(y_test, y_pred_test, pos_label = 1)\n",
    "    auc_roc1 = auc(fpr, tpr)\n",
    "    list_auc.append(auc_roc1)\n",
    "\n",
    "    tprs.append(interp(mean_fpr, fpr, tpr))\n",
    "    tprs[-1][0] = 0.0\n",
    "    aucs.append(auc_roc1)\n",
    "    plt.plot(fpr, tpr, lw=1, alpha=0.3)\n",
    "\n",
    "    # Resetting model weights and clearing the session\n",
    "    tf.keras.backend.clear_session()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "y_test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "sns.set_style(\"whitegrid\")\n",
    "plt.plot([0, 1], [0, 1], linestyle='--', lw=1, color='r',\n",
    "         label='Random guessing', alpha=.8)\n",
    "\n",
    "mean_tpr = np.mean(tprs, axis=0)\n",
    "mean_tpr[-1] = 1.0\n",
    "mean_auc = auc(mean_fpr, mean_tpr)\n",
    "std_auc = np.std(aucs)\n",
    "plt.plot(mean_fpr, mean_tpr, color='b',\n",
    "         label=r'Mean ROC (AUC = %0.2f $\\pm$ %0.2f)' % (mean_auc, std_auc),\n",
    "         lw=1, alpha=.8)\n",
    "\n",
    "std_tpr = np.std(tprs, axis=0)\n",
    "tprs_upper = np.minimum(mean_tpr + std_tpr, 1)\n",
    "tprs_lower = np.maximum(mean_tpr - std_tpr, 0)\n",
    "plt.fill_between(mean_fpr, tprs_lower, tprs_upper, color = 'grey', alpha = .2,\n",
    "                 label = r'$\\pm$ 1 std. dev.')\n",
    "\n",
    "plt.xlim([-0.05, 1.05])\n",
    "plt.ylim([-0.05, 1.05])\n",
    "plt.xlabel('False Positive Rate')\n",
    "plt.ylabel('True Positive Rate')\n",
    "plt.title('Receiver Operating Characteristic')\n",
    "plt.legend(loc = \"lower right\")\n",
    "plt.savefig('output_data/auc_avg.pdf', bbox_inches = 'tight')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
